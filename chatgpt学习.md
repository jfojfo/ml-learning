# chatgpt学习

## Transformer详解

[https://zhuanlan.zhihu.com/p/420820453](https://zhuanlan.zhihu.com/p/420820453)

[请至钉钉文档查看附件《层层剥开Transformer\_v1.3.1.pdf》](https://alidocs.dingtalk.com/i/nodes/NZQYprEoWo0ApMGPcgNjBmGPV1waOeDk?iframeQuery=anchorId%253DX02ljkw37zhgfcfobtsywj)

## GLM论文训练

[https://github.com/THUDM/GLM/tree/main](https://github.com/THUDM/GLM/tree/main)

## 【Instruction Tuning】ChatGLM 微调实战（附源码）

[https://zhuanlan.zhihu.com/p/625468667](https://zhuanlan.zhihu.com/p/625468667)

## 利用chatgpt生成训练数据

参考：[https://github.com/wdkwdkwdk/CLONE\_DK/blob/main/blog\_handle\_readme.md](https://github.com/wdkwdkwdk/CLONE_DK/blob/main/blog_handle_readme.md)

    我会给你一个我写的文本，你需要将文本转换成多个聊天形式的问答对，并以json格式返回，问题的字段为instruction，回答的字段名称为 output ，例如：\n[\n    {\n        \"instruction\": \"人好少啊\",\n        \"input\": \"\",\n        \"output\": \"这是第四十个群\"\n    },\n    {\n        \"instruction\": \"请问这叫什么风格？\",\n        \"input\": \"\",\n        \"output\": \"安迪霍沃尔\"\n    }\n]
    

    [
      {
        "instruction": "这是一个意识永存的世界是什么意思？",
        "input": "",
        "output": "在这个世界中，人的意识可以独立存在，即使身体死亡，灵识仍然存在。"
      },
      {
        "instruction": "对于一个永恒的生命，没有存在的意义的支撑会比死亡更可怕吗？",
        "input": "",
        "output": "是的，一个永恒的生命如果没有存在的意义支撑，永生将比死亡更可怕。"
      },
      {
        "instruction": "在技术打破各种约束将人类带入无限时，人类却给自己设定了一项限制是什么？",
        "input": "",
        "output": "每个灵识所存的躯体一旦死亡，这个灵识在抽离出去之后，要消除记忆，然后进入到下一个轮回继续探索体验。"
      },
      {
        "instruction": "人们为什么要利用地球上动物的躯体，将灵识灌入？",
        "input": "",
        "output": "由于最后一具原先的躯壳早已消亡在历史长河，为了让灵识得到继续存在，人们开始利用地球上动物的躯体，将灵识灌入其中。"
      },
      {
        "instruction": "人类是如何进化为现在的形态的？",
        "input": "",
        "output": "人类进化为现在的形态，是通过将灵识灌入古猿的躯体中，形成智人，并逐渐进化为现在的人类。"
      },
      {
        "instruction": "人类文明史上最伟大的一次自我限制是什么？",
        "input": "",
        "output": "人类文明史上最伟大的一次自我限制，是将灵识灌入古猿的躯体中，形成智人，并逐渐进化为现在的人类。"
      },
      {
        "instruction": "人类在追求不断进步的同时，还在不断反思探寻什么？",
        "input": "",
        "output": "人类在追求不断进步的同时，也在不断反思探寻存在的意义。"
      }
    ]

## Lil'Log（不错的blog）

[The Transformer Family Version 2.0](https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/)

[请至钉钉文档查看附件《The Transformer Family Version 2.0 \_ Lil'Log.pdf》](https://alidocs.dingtalk.com/i/nodes/NZQYprEoWo0ApMGPcgNjBmGPV1waOeDk?iframeQuery=anchorId%253DX02ljl926qlrvsnx13uxr)

[Prompt Engineering](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)

[Large Transformer Model Inference Optimization](https://lilianweng.github.io/posts/2023-01-10-inference-optimization/)

## LLaMA 2 Math微调方法学习

[https://github.com/nlpxucan/WizardLM/tree/main/WizardMath](https://github.com/nlpxucan/WizardLM/tree/main/WizardMath)